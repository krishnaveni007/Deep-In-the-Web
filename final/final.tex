\documentclass[12pt]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage[title]{appendix}
\usepackage{graphicx, listings, titlesec, cite, authblk, mdframed, floatrow, hyperref}
\usepackage{graphicx, listings, titlesec, cite, authblk, mdframed, floatrow, hyperref}

\titleformat{\section}
  {\normalfont\fontsize{12}{15}\bfseries}{\thesection}{1em}{}

\title{Deep in the Web: using deep learning methods to predict Problematic Internet Use in today's youth}
\author[1]{Evan Matthews}
\author[1]{Vikram Ramavarapu}
\author[1]{Krishnaveni Unnikrishnan}
\affil[1]{CS 412 Group G6}
\date{December 11, 2024}

% commands
\newcommand{\todo}{\textcolor{red}{TODO:}~}
\newfloatcommand{capbtabbox}{table}[][\FBwidth]

\begin{document}

\maketitle

\begin{abstract}
    The Internet's pervasive role in modern life has raised concerns about Problematic Internet Use (PIU), particularly among children and teens. 
    Our research aims to predict early signs of PIU using machine learning techniques applied to data from the Child Mind Institute's Healthy Brain Network. 
    This study employs a comprehensive methodology combining both cross-sectional and time-series data for future analysis. 
    Initial results from multiple models, including Random Forest, XGBoost, SVM, and Feed Forward Neural Networks, demonstrate promising accuracy rates, with XGBoost achieving the highest mean accuracy of 0.682. 
    Our project experimentation is structured in three phases: data preprocessing, initial model evaluation, and fine-feature reevaluation. 
    The methodology incorporates innovative approaches such as sequential modeling for time-series data and ensemble techniques combining cross-sectional and sequential models. 
    Preliminary findings suggest that machine learning can effectively predict PIU severity using quantitative measures compared to traditional assessments. 
    This research contributes to the growing field of digital health by providing a data-driven approach to identifying at-risk youth for PIU.
    Code for the analysis can be found at this \href{https://github.com/ematth/DeepInTheWeb}{Github Repository}.
\end{abstract}
\pagebreak

\section{Introduction}

  The Internet has become an integral part of our daily lives, with people of all ages spending a significant amount of time online. 
  This trend has given rise to concerns about the potential impacts of excessive internet use, particularly on children and teens.
  Problematic Internet Use (PIU) is a condition characterized by excessive or poorly controlled preoccupations, urges, or behaviors regarding computer use and internet access that lead to impairment or distress \cite{Pettorruso2020-qt}. 
  PIU has been associated with a range of mental health issues, including depression, anxiety, and impulsivity \cite{Cash2012-rb}.
  As such, identifying early signs of PIU in children and teens is crucial for prevention and intervention.
  Despite having multiple studies showing the negative effects of excessive internet use, exact details about PIU warning signs and the most at-risk individuals are still unknown.
  These studies can be useful, but they also introduce biases and often fail to show the true factors which correlate a participant's estimated internet impact \cite{Restrepo2020-pb,Aboujaoude2010-mc}.
  In this project, we aim to predict early signs of PIU in children and teens using machine learning techniques, leveraging data from the Child Mind Institute's Healthy Brain Network.
  The project plan consists of three phases: data preprocessing, initial model evaluation, and fine-feature reevaluation.
  We will submit our work to the Child Mind Institute's (CMI) Kaggle competition on PIU prediction at a later date.

\section{Motivation}

  With the rise of machine learning and pattern prediction models, the ability to analyze and predict upon more complex data and parameters becomes much more approachable.
  Likewise, child development is a multi-facted situation in which parenting and environmental factors can lead to an incredibly high number of outcomes.
  This field has had great strides in classical research, but a more modern approach could lead to significant development in the success of future generations.
  Additionally, predictions against an extensive number of possible outcomes like this represents a current roadblock in machine learning- 
  that is, how modern predictive models can adapt to an ever-increasing set of parameters and decreasing set of training data.
  Finally, child psychology is interested in recognizing patterns in early behavior in order to reduce the impact of harmful effects from a child's environment.

  Despite having multiple studies showing the negative effects of excessive internet use, exact details about PIU warning signs and the most at-risk individuals are still unknown.
  These studies can be useful, but their results focus primarily on written or binary feedback from students or parents. 
  Additionally, they introduce biases and often fail to show the true factors which correlate a participant's estimated internet impact \cite{Restrepo2020-pb,Aboujaoude2010-mc}.

  Another major drawback of assessing PIU is in its subjective nature. 
  Problematic internet use is characterized by many different variables that are hard to measure. 
  As such, using quantitative measures such as the Severity Impairment Index (SII) allow for the application of data mining methods to aid in the classification of PIU severity. 
  Moreover, other measurable attributes such as sleep quality and duration, physical activity level, and duration of internet usage can all be used to understand correlations with PIU.
  This project intends to rectify these issues by using a machine-learning approach to predict early signs of PIU using a wider range of variables on children and teens.

\section{Related Work}

  Research on Problematic Internet Use (PIU) has gained significant attention due to its increasing prevalence and association with various psychological and behavioral issues. 
  Early investigations into PIU highlighted its similarities with substance use disorders, impulse control disorders, and obsessive-compulsive disorder.
  Studies have revealed concerning prevalence rates between 1.5\% and 8.2\% in the United States and Europe, emphasizing the growing social impact of this condition \cite{Cash2012-rb}. 
  The relationship between PIU and psychiatric disorders has been extensively documented, with research showing significant associations with depressive disorders and attention-deficit/hyperactivity disorder (ADHD). 
  A notable study found that individuals with PIU were more than twice as likely to have depressive disorders $(aOR = 2.43)$, and showed increased likelihood of having ADHD combined presentation $(aOR = 1.91)$ and Autism Spectrum Disorder $(aOR = 2.24)$ \cite{Restrepo2020-pb}.

  Recent investigations have focused on understanding the personality profiles and emotional factors contributing to PIU. Research has identified specific personality traits associated with PIU, including lower scores in novelty seeking, harm avoidance, and reward dependence. 
  Additionally, emotional dysregulation has emerged as a significant factor, with studies suggesting that PIU may serve as a behavioral mechanism for escaping negative affects.
  Treatment approaches for PIU have primarily centered on addressing comorbid conditions, with cognitive behavioral therapy and selective serotonin reuptake inhibitors showing promise as potential interventions.
  However, researchers emphasize that detailed treatment guidelines require further investigation, particularly given interactions between PIU and various psychological disorders.

  Currently, the field continues to evolve, and debates haved continued regarding diagnostic criteria and classification. While the Internet's positive impact on well-being is widely acknowledged, the pathological aspects of its use remain understudied, particularly regarding subtle psychological changes such as online disinhibition. 
  This highlights the need for additional research into the pathophysiology, epidemiology, natural course, and treatment of PIU to develop more effective intervention strategies.
  In terms of our current work, given that the original scope of the project was accepted, we are pressing forward with this plan with no significant changes.
  The most crucial critique provided- that the validation plan and evaluation metric were not clear- are likewise addressed in the methodology section.

\section{Methodology}

  Data for this project has two components: cross-sectional, and sequential (time-series). The cross-sectional data is per participant and contains fields described in the following table.
  Each sequential dataset is per participant and each entry of the dataset represents the status of the participant's heartrate monitor at a given point in time. 
  PCIAT is the Parent-Child Internet Addiction Test score, which is used to compute the Severity of Internet Addiction Index (SII) score. 
  The SII score is the target variable for this project. For the description of fields in the time-series dataset, see Table \ref{table:fields}.

  The project is divided into three phases: data preprocessing, initial model evaluation, and fine-feature reevaluation.
  The data preprocessing phase entails dropping survey-based fields used to compute PCIAT, which is then used to compute the SII, as our model's intention is to compute SII directly from the other metrics.
  Missing values in the data are filled using iterative imputation, and the missing SII values are filled in using K-Nearest Neighbors $(k=5)$.

  Multiple models are evaluated on the cross-sectional data: Random Forest, XGBoost, SVM, and a feed forward neural network. 
  After this, a sequential model, evaluated amongst transformers or auto-encoders, is trained on the time-series data. 
  The sequential model allows us to compute an embedding of the time-series data, which will be used as an additional feature in the cross-sectional model.
  The final model is an ensemble of the cross-sectional and sequential models, with the sequential model's embedding as an additional feature in the cross-sectional model. 
  The classifier model is retrained on the concatenated dataset, to predict the SII.
  Finally, validation of the trained models is performed using 10-fold cross-validation, with the best model selected based on performance metrics.

  After comparing classifiers and selecting the best model, we land on the architecture shown in Figure \ref{'table:architecture'}.
  First, XGBoost is trained on the cross-sectional data, where missing values are filled using label propagation. 
  A transformer encoder is trained on the time-series data using reconstruction loss, and the encoder is used to compute an embedding of the time-series data. 
  The embedding is concatenated with the cross-sectional data, and the XGBoost model is retrained on the concatenated dataset.
  In the testing phase, for a datapoint that has a time-series component, the transformer encoder is used to compute the embedding, 
  which is then concatenated with the cross-sectional data and fed into the XGBoost model to predict the SII. 
  If time-series data is not available, the XGBoost model is used to predict the SII directly from the cross-sectional data.

  \begin{figure}
    \centering
    \includegraphics[width=0.55\linewidth]{images/schematic.png}
    \caption{Model architecture}
    \label{'table:architecture'}
  \end{figure}



  \subsection{Results} 
  \subsubsection{Cross-Sectional Data}

    Preliminary results of 10-fold cross-validation provide insight into the performance consistency of each model- 
    Random Forest Classifier, XGBoost Classifier, Support Vector Classifier, and Feed Forward Neural Network across different subsets of the dataset. 
    This method helps ensure that the reported accuracy is not overly dependent on any particular training subset, 
    giving a more reliable view of how each model would perform in a real-world setting. 
    These results are summarized in Table \ref{table:10foldcv-results} and Table \ref{'table:mean_accuracy_table'}.

    \begin{table}[h!]
        \centering
        \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|}
            \hline
            \textbf{Model} & \textbf{Fold 1} & \textbf{Fold 2} & \textbf{Fold 3} & \textbf{Fold 4} & \textbf{Fold 5} & \textbf{Fold 6} & \textbf{Fold 7} & \textbf{Fold 8} & \textbf{Fold 9} & \textbf{Fold 10} \\
            \hline
            RF & 0.684 & 0.682 & 0.682 & 0.674 & 0.687 & 0.674 & 0.684 & 0.707 & 0.649 & 0.672 \\
            \hline
            XGB& 0.689 & 0.667 & 0.669 & 0.689 & 0.682 & 0.684 & 0.674 & 0.732 & 0.636 & 0.694 \\
            \hline
            SVC & 0.649 & 0.657 & 0.646 & 0.649 & 0.649 & 0.646 & 0.649 & 0.649 & 0.654 & 0.652 \\
            \hline
            FFN & 0.710 & 0.649 & 0.669 & 0.692 & 0.689 & 0.684 & 0.687 & 0.674 & 0.649 & 0.694 \\
            \hline
        \end{tabular}%
        }
        \caption{10-Fold Cross-Validation Results for Each Model}
        \label{table:10foldcv-results}
    \end{table}

    \begin{table}[h!]
        \centering
        \begin{tabular}{|l|c|}
            \hline
            \textbf{Model} & \textbf{Mean Accuracy} \\
            \hline
            Random Forest Classifier & 0.680 \\
            \hline
            XGBoost Classifier & 0.682 \\
            \hline
            Support Vector Classifier & 0.650 \\
            \hline
            Feed Forward Neural Network & 0.680 \\
            \hline
        \end{tabular}
        \caption{Mean Accuracy for Each Model}
        \label{'table:mean_accuracy_table'}
    \end{table}


    % \begin{figure}[h!]
    %     \centering
    %     \includegraphics[scale=0.8]{"./images/model_accuracy.jpg"}
    %     \caption{Model accuracy of Feed-Forward Neural Network}
    % \end{figure}

    Using hypothesis testing, we conclude that XGBoost model is significantly better than the other models based on a Student's t-test at significance level $\alpha=5\%$ and number of parameters to be trained.

  \subsubsection{Sequential Data}
  
      The sequential model was trained on the time-series data using a transformer encoder. 
      The model was trained using reconstruction loss, and the encoder was used to compute an embedding of the time-series data.
      The loss curve for the transformer model is shown in Figure \ref{fig:transformer_loss}.

      \begin{figure}[!htb]
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[scale=0.22]{"./images/transformer_loss.jpeg"}
            \caption{Transformer reconstruction loss over time; model accuracies, with and without extra features.}
            \label{fig:transformer_loss}
        \end{minipage}
        \hfill
        \begin{minipage}{0.48\textwidth}
            \centering
            \includegraphics[width=\linewidth]{"./images/model_bars.png"}
            % \caption{Model accuracies, with and without extra features.}
            \label{fig:transformer_accuracy}
        \end{minipage}
    \end{figure}

      After 10 epochs of training, each patient with time-series data has an embedding computed, which is then used as an additional feature in the cross-sectional XGBoost model.
      The XGBoost model with the same maximum depth ($depth=15$), when trained on the concatenated dataset, achieves a lower validation accuracy than the model trained on the cross-sectional data alone. 
      However, the model achieved 100\% accuracy on the training data, suggesting overfitting.
      As such, the XGBoost model was retrained on the concatenated dataset with a lower maxmimum depth ($depth=10$).
      The 10-fold cross-validation results for the retrained model are shown in Figure \ref{fig:transformer_accuracy}.

      

\section{Discussion and Conclusion}

To conclude, results concerning both cross-sectional and sequential data have shown great promise with respect to accuracy optimization.
In particular, we show that our method of including additional features from the sequential data can improve the overall accuracy of the model by 10 percent.
And while this method may seem trivial and obvious to use, its implications were not fully understood by our team until we performed quantitative comparisons.

In terms of the Kaggle competition, we are confident that our model will perform well, given the results of our cross-validation and the improvements made by learning on sequential data.
However, we also understand that, due to time constraints and outside factors beyond our control, our model may not be the best and could use further improvements for medal qualification.

Lastly, while we planned to produce model accuracies on a feature-optimizing basis, we were unable to do so due to time constraints.
We believe that this would have been a valuable addition to our project, and we hope to include this in future work.
Architecture diagrams and relevant code can be provided upon request.

% Code and related documentation can be found at \url{https://github.com/ematth/DeepInTheWeb}.


\pagebreak
\nocite{*}
\bibliographystyle{plain}
\bibliography{bibliography}

\pagebreak

\include{appendix.tex}

\end{document}